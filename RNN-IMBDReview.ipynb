{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc64bc58",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks (RNN) are the state of the art algorithm for sequential data and are used by Apple's Siri and and Google's voice search. It is the first algorithm that remembers its input, due to an internal memory, which makes it perfectly suited for machine learning problems that involve sequential data. \n",
    "\n",
    "Recurrent neural networks (RNN) are a class of neural networks that are helpful in modeling sequence data. Derived from feedforward networks, RNNs exhibit similar behavior to how human brains function. Simply put: recurrent neural networks produce predictive results in sequential data that other algorithms canâ€™t.\n",
    "\n",
    "Feed-forward neural network:\n",
    "1.Cannot handle sequential data\n",
    "2.Considers only the current input\n",
    "3.Cannot memorize previous inputs\n",
    "\n",
    "An RNN can handle sequential data, accepting the current input data, and previously received inputs. RNNs can memorize previous inputs due to their internal memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3847ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb135187",
   "metadata": {},
   "source": [
    "In this Notebook, I will train a \"vanilla\" RNN to predict the sentiment on IMDB reviews.  Our data consists of 25000 training sequences and 25000 test sequences.  The outcome is binary (positive/negative) and both outcomes are equally represented in both the training and the test set.\n",
    "\n",
    "Keras provides a convenient interface to load the data and immediately encode the words into integers (based on the most common words).  This will save us a lot of the drudgery that is usually involved when working with raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743a0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used in loading the data, picks the most common (max_features) words\n",
    "max_features = 20000 \n",
    "# maximum length of a sequence - truncate after this\n",
    "maxlen = 30  \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0327ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "## Load in the data.  The function automatically tokenizes the text into distinct integers\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c8f828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ebe997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 30)\n",
      "x_test shape: (25000, 30)\n"
     ]
    }
   ],
   "source": [
    "# This pads (or truncates) the sequences so that they are of the maximum length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cef0300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4,   277,   199,   166,   281,     5,  1030,     8,    30,\n",
       "          179,  4442,   444, 13772,     9,     6,   371,    87,   189,\n",
       "           22,     5,    31,     7,     4,   118,     7,     4,  2068,\n",
       "          545,  1178,   829],\n",
       "       [  991,     7,  3002,     4,   425,     9,    73,  2218,   549,\n",
       "           18,    31,   155,    36,   100,   763,   379,    20,   103,\n",
       "          351,  5308,    13,   202,    12,  2241,     5,     6,   320,\n",
       "           46,     7,   457],\n",
       "       [  218,  4843,   629,    42,  3017,    21,    48,    25,    28,\n",
       "           35,   534,     5,     6,   320,     8,   516,     5,    42,\n",
       "           25,   181,     8,   130,    56,   547,  3571,     5,  1471,\n",
       "          851,    14,  2286],\n",
       "       [  276,    23,  1456,   255,     4,  3612,   449,    61,   558,\n",
       "           12,    16,     6,     2,    17,     8,    63,    31,    16,\n",
       "          433,    51,     9,   170,    23,    11,  1898,   134,   504,\n",
       "         1195,  1195,  1195],\n",
       "       [   75,    28,     9,    14,     2,    10,    10,   884,  1866,\n",
       "            9,     4,  4017,  2809,    10,    10,   719,     2,    70,\n",
       "         2885,     4,  2552,     2,  4430,   175,  6640,    11,     4,\n",
       "            2,   543,  1609]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10:15,:]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb440b8",
   "metadata": {},
   "source": [
    "# Building RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10b1e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's build a RNN\n",
    "\n",
    "rnn_hidden_dim = 5\n",
    "word_embedding_dim = 50\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))  #This layer takes each integer in the sequence and embeds it in a 50-dimensional vector\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
    "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
    "                    activation='relu',\n",
    "                    input_shape=x_train.shape[1:]))\n",
    "\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aa4bf",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c71ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 5)                 280       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,000,286\n",
      "Trainable params: 1,000,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Note that most of the parameters come from the embedding layer\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83678191",
   "metadata": {},
   "source": [
    "#### Summary Of Parameters:\n",
    "    Embedding - Each word is a vector of length 50. 20000*50 =1000000\n",
    "    Simple_RNN - 50*5+5 = 255 , One state to another 5*5 =25 ,therfore 280\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52c94654",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr = .0001)\n",
    "\n",
    "model_rnn.compile(loss='binary_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d69c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 25s 992us/step - loss: 0.6534 - accuracy: 0.6275 - val_loss: 0.5957 - val_accuracy: 0.6863\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 23s 927us/step - loss: 0.5469 - accuracy: 0.7267 - val_loss: 0.5367 - val_accuracy: 0.7266\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 23s 925us/step - loss: 0.4874 - accuracy: 0.7705 - val_loss: 0.5033 - val_accuracy: 0.7490\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.4472 - accuracy: 0.7937 - val_loss: 0.4874 - val_accuracy: 0.7562\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.4191 - accuracy: 0.8105 - val_loss: 0.4677 - val_accuracy: 0.7712\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 24s 944us/step - loss: 0.3984 - accuracy: 0.8207 - val_loss: 0.4588 - val_accuracy: 0.7796\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 24s 962us/step - loss: 0.3835 - accuracy: 0.8314 - val_loss: 0.4507 - val_accuracy: 0.7846\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 24s 960us/step - loss: 0.3721 - accuracy: 0.8362 - val_loss: 0.4486 - val_accuracy: 0.7853\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.3640 - accuracy: 0.8392 - val_loss: 0.4470 - val_accuracy: 0.7880\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 25s 983us/step - loss: 0.3568 - accuracy: 0.8437 - val_loss: 0.4479 - val_accuracy: 0.7893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f846ecdccf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5233577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 111us/step\n",
      "Test score: 0.44788544396400454\n",
      "Test accuracy: 0.7893199920654297\n"
     ]
    }
   ],
   "source": [
    "score, acc = model_rnn.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597ff25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
